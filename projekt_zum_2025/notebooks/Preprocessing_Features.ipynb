{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d05b8c-c8b0-4d72-9f76-746f5aa459da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bibliotek\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c60b41-4792-4f7d-a3b3-afc7bd145393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytywanie danych\n",
    "train = pd.read_csv(\"../data/raw/emotion_train.csv\")\n",
    "valid = pd.read_csv(\"../data/raw/emotion_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2e4581f-8c9c-40e3-ae75-3a708fae3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# czyszczenie tekstu\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "for df in [train, valid]:\n",
    "    df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247c929a-bd09-4bdb-bb52-b1f0edbb8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana tekstu na numery (wektoryzacja)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train['clean_text'])\n",
    "X_valid = tfidf.transform(valid['clean_text'])\n",
    "\n",
    "y_train = train['label']\n",
    "y_valid = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1d0079d-81af-40f4-9a5e-89a895cda8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis danych\n",
    "X_train_dense = X_train.toarray()\n",
    "X_valid_dense = X_valid.toarray()\n",
    "\n",
    "train[['clean_text', 'label']].to_csv(\"../data/processed/train_clean.csv\", index=False)\n",
    "valid[['clean_text', 'label']].to_csv(\"../data/processed/valid_clean.csv\", index=False)\n",
    "\n",
    "np.save(\"../data/processed/X_train.npy\", X_train_dense)\n",
    "np.save(\"../data/processed/X_valid.npy\", X_valid_dense)\n",
    "\n",
    "y_train.to_csv(\"../data/processed/y_train.csv\", index=False)\n",
    "y_valid.to_csv(\"../data/processed/y_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac06b57d-9a39-4f26-bad9-a4059bddf336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zapis wektoryzacji\n",
    "import joblib\n",
    "joblib.dump(tfidf, \"../models/tfidf_vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352817bf-987d-4b56-b43f-1f89c122a619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
